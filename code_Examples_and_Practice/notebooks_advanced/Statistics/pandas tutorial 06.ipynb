{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6: Combining dataframe\n",
    "\n",
    "When working with multiple datasets during a project, there will come a point where you might wish to merge your dataframes together to have a better view and understanding of your data. \n",
    "\n",
    "In this tutorial, we will cover two pandas functions, and they are [concat](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html) and [merge](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html) that are used to combine dataframes.\n",
    "\n",
    "Note that you sometimes you will might see functions like [join](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.join.html) and [append](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.append.html#pandas.DataFrame.append) being used in other people's notebooks. However, I will not be discussing these two functions but just know they are the equivalent of concat and merge respectively.\n",
    "\n",
    "I would recommend that you only learn concat and merge as they should be sufficient to handle all the scenarios that you will ever come across.\n",
    "\n",
    "With that being said, let's proceed with the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from pandas.core.computation.check import NUMEXPR_INSTALLED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concat\n",
    "\n",
    "Concat is short for concatenate. This function allows to stack two separate dataframes both vertically and horizontally.\n",
    "\n",
    "Let's observe this with an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'Name': ['Vicky', 'Bill'], 'Age': [12, 46]})\n",
    "df2 = pd.DataFrame({'Name': ['John', 'Sabrina'], 'Age': [37, 25]})\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an argument called axis within the concat function that you can use to specify which way you would like to stack your dataframe. 1 means horizontal whereas 0 means vertical. If you do not specify, pandas assumes 0 as its default. \n",
    "\n",
    "You can also use the ignore index function if you would like a sequential index column in the new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat horizontally\n",
    "\n",
    "pd.concat([df1, df2], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat vertically and ignore index\n",
    "\n",
    "df3 = pd.concat([df1, df2], axis = 0,ignore_index = True)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is another argument called join which allows you to stack dataframes only based on the columns shared by two dataframes.\n",
    "\n",
    "To demonstrate this, suppose we have a new dataframe with an extra column for hobby."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df4 = pd.DataFrame({'Name': ['Tyler', 'Natalie'], \n",
    "                    'Age': [28, 39], \n",
    "                    'Hobby': ['Swimming', 'Reading']})\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df3, df4], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outer is the default for the join argument\n",
    "pd.concat([df3, df4], join = 'outer', ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9 = pd.DataFrame({\"adress\": [14,48,78], \"level\": [\"College\", \"School\", \"Employee\"]})\n",
    "\n",
    "df11 = pd.concat([df3,df9], join = \"outer\" , ignore_index=True)\n",
    "print(df11[\"Age\"].dtype)\n",
    "df11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outer does not consider any differences in columns between two dataframe. Because df3 does not have a hobby column, pandas will automatically fill them with null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner stacks only the columns that are shared between the two dataframes\n",
    "#Intersection \n",
    "pd.concat([df3, df4], join = 'inner', ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because df3 does not have the hobby column, pandas will not show that column in the combined dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge\n",
    "\n",
    "To demonstrate the idea of merge, let's first create two samples dataframe of a retail store. One for sales data and one for customer profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "\n",
    "startingDate = date(2019, 7, 1)\n",
    "endingDate = date(2020, 6, 30)\n",
    "diff = endingDate - startingDate\n",
    "\n",
    "dates = []\n",
    "\n",
    "for k in range(diff.days + 1):\n",
    "    dates.append(startingDate + timedelta(days = k))\n",
    "    \n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = date(2024, 12 , 25)\n",
    "for i in range(5):\n",
    "    current_Date = start_date + timedelta(days=i)\n",
    "\n",
    "print(current_Date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The choices() method returns a list with the randomly selected element from the specified sequence.\n",
    "\n",
    "You can weigh the possibility of each result with the weights parameter or the cum_weights parameter.\n",
    "\n",
    "The sequence can be a string, a range, a list, a tuple or any other kind of sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two dataframes, one for sales and one for customer profile\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "lifestage = ['Young', 'Adults', 'Family', 'Senior']\n",
    "\n",
    "stores = ['Melbourne CBD', 'Carlton', 'Fitzroy', 'Collingwood',\n",
    "          'Richmond', 'Doncaster', 'Kew', 'Prahran', \n",
    "          'South Yarra', 'Docklands', 'Bundoora', 'Ivanhoe',\n",
    "          'Glen Waverly', 'Dandenong', 'Frankston']  \n",
    "\n",
    "sales = pd.DataFrame({'Date': random.choices(dates, k = 1000), \n",
    "                      'Customer ID': random.choices(list(range(1, 101)), k = 1000), \n",
    "                      'Store': random.choices(stores, k = 1000), \n",
    "                      'Sales': random.choices(list(range(1, 101)), k = 1000)})\n",
    "\n",
    "\n",
    "customers = pd.DataFrame({'Customer ID': list(range(1, 101)), \n",
    "                          'Customer Lifestage': random.choices(lifestage, k = 100)})\n",
    "\n",
    "# Let's look at sales\n",
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date is not in order so sort data by date\n",
    "\n",
    "sales.sort_values(by = 'Date', inplace = True, ignore_index = True)\n",
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 100 unique customer ID which means that they are unique to each row\n",
    "\n",
    "customers['Customer ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Customer ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select sales made by customer with customer ID number 1\n",
    "\n",
    "sales.loc[sales['Customer ID'] == 1, :].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers.loc[customers['Customer ID'] == 1, :].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes together\n",
    "combined = pd.merge(sales, customers)\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['Customer Lifestage'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of sales data is: \", sales.shape)\n",
    "print(\"Shape of customer data is: \", customers.shape)\n",
    "print(\"Shape of the combined dataframe is: \", combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.loc[combined['Customer ID'] == 1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, merge has successfully joined the two dataframes together based on a shared column which is customer ID.\n",
    "\n",
    "The combined dataframe has the same number of rows as the sales dataframe but with an additional column, customer lifestage which came from the customer dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to explore the how argument within the merge function which allows you to specify the direction in which you would like to merge your dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = pd.DataFrame({'Color': ['Red', 'Blue', 'Green'], 'Size': ['M', 'S', 'L']})\n",
    "gender = pd.DataFrame({'Color': ['Red', 'Blue', 'Yellow'], 'Sex': ['Female', 'Female', 'Male']})\n",
    "size               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inner and outer are very similar to what we have seen in the concat section earlier in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Only show rows where there is a match in the column\n",
    "# Red and blue are present in both dataframes\n",
    "\n",
    "pd.merge(size, gender, how = 'inner')  #Intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all the rows and fill rows with null values when there is no match\n",
    "# There is no sex info on green colour and there is no size info on yellow colour\n",
    "\n",
    "pd.merge(size, gender, how = 'outer')  # Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left and right on the other hand allows you to specify which dataframe to keep when there is no matching rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Keep everything that is on the left dataframe which is df1 in this example\n",
    "# Fill in sex info for rows that have matches with df2 and if there is none e.g. green colour, fill null value\n",
    "\n",
    "pd.merge(size, gender, how = 'left') #size - gender (difference rule in set theory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep everything that is on the right dataframe which is df2 in this example\n",
    "# Fill in size info for rows that have matches with df1 and if there is none e.g. yellow colour, fill null value\n",
    "\n",
    "pd.merge(size, gender, how = 'right') #gender - size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
